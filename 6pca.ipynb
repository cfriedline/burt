{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../include_utils/\")\n",
    "\n",
    "from ipyparallel import Client\n",
    "import ipyparallel as ipp\n",
    "import os, time\n",
    "import include_utils as u\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import numbers\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "import vcf\n",
    "from sklearn import preprocessing\n",
    "from subprocess import Popen, PIPE\n",
    "import seaborn as sns\n",
    "from IPython.display import FileLink\n",
    "#import urllib2\n",
    "import urllib.request as urllib2\n",
    "import urllib\n",
    "import dill\n",
    "import traceback\n",
    "from pandas import Series, DataFrame\n",
    "import gzip\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=pd.io.pytables.PerformanceWarning)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from Bio import SeqIO\n",
    "import pysam\n",
    "from collections import OrderedDict, namedtuple\n",
    "import operator\n",
    "import multiprocessing as mp\n",
    "import pickle\n",
    "from IPython.display import FileLink, FileLinks, display\n",
    "\n",
    "samtools = \"/home/cfriedline/gpfs/src/samtools-1.3/samtools\"\n",
    "bcftools = \"/home/cfriedline/gpfs/src/bcftools-1.3/bcftools\"\n",
    "picard = \"/home/cfriedline/gpfs/src/broadinstitute-picard-03a1d72/dist/picard.jar\"\n",
    "java = \"/home/cfriedline/g/src/jdk1.8.0_60/bin/java\"\n",
    "perl = \"/home/cfriedline/gpfs/opt/ActivePerl-5.18/bin/perl\"\n",
    "\n",
    "vcfutils = \"perl /home/cfriedline/g/src/bcftools-1.3/vcfutils.pl\"\n",
    "vcftools = \"/home/cfriedline/bin/vcftools\"\n",
    "bcftools = \"/home/cfriedline/gpfs/src/bcftools-1.3/bcftools\"\n",
    "tabix = \"/home/cfriedline/gpfs/src/htslib-1.3/tabix\"\n",
    "bgzip = \"/home/cfriedline/gpfs/src/htslib-1.3/bgzip\"\n",
    "\n",
    "\n",
    "def setup_r():\n",
    "    os.environ['R_HOME'] = '/home/cfriedline/g/R3/lib64/R'\n",
    "    os.environ['LD_LIBRARY_PATH'] = \"%s/lib:%s:%s\" % (os.environ['R_HOME'], \n",
    "                                                   os.environ['LD_LIBRARY_PATH'],\n",
    "                                                     \"/home/cfriedline/lib64\")\n",
    "\n",
    "setup_r()\n",
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "r = robjects.r\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%reload_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "species = [\"T\", \"E\", \"P\", \"G\"]\n",
    "ni_dir = \"/gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3\"\n",
    "imp_dir = \"/gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3/beagle40\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vcfs = []\n",
    "for spp in species:\n",
    "    for d in [ni_dir, imp_dir]:   \n",
    "        d = os.path.join(d, spp)\n",
    "        vcfs.append(os.path.join(d, \"isect_snps.recode.vcf.gz_sorted.vcf.gz_thin.recode.vcf.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vcfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for v in vcfs:\n",
    "    !$vcftools --gzvcf $v --012 --out $v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12s = [\"%s.012\" % x for x in vcfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rc = Client(profile=\"sge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_z12_df(z12_file):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    print(z12_file)\n",
    "    indv_file = \"%s.indv\" % z12_file\n",
    "    pos_file = \"%s.pos\" % z12_file\n",
    "    z12_data = []\n",
    "    for i, line in enumerate(open(z12_file)):\n",
    "        line = line.strip()\n",
    "        line = [int(x) for x in line.split(\"\\t\")]\n",
    "        z12_data.append(np.array(line))\n",
    "    z12_data = np.array(z12_data)\n",
    "    p = pd.read_csv(pos_file, sep=\"\\t\", names=['contig', 'pos'])\n",
    "    i = pd.read_csv(indv_file, names=['sample_name'])\n",
    "    df = pd.DataFrame(z12_data)\n",
    "    df = df.drop(0, axis=1)\n",
    "    df.columns = p.apply(lambda x: \"%s_%s\" % (x.contig, x.pos), axis=1)\n",
    "    df.index = [x for x in i.sample_name]\n",
    "    return z12_file, df\n",
    "#z12_dfs = [get_z12_df(x) for x in z12s]\n",
    "#z12_dfs = [x[keep_snps.index] for x in z12_dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dv, lv = u.get_views(rc)\n",
    "len(dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dv['get_z12_df'] = get_z12_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z12_jobs = lv.map_async(get_z12_df, z12s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_jobs.completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_dfs = {}\n",
    "for j in z12_jobs:\n",
    "    z12_dfs[j[0]] = j[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_key = '/gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3/E/isect_snps.recode.vcf.gz_sorted.vcf.gz_thin.recode.vcf.gz.012'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_dfs[test_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_pheno():\n",
    "    pheno = pd.read_csv(\"/home/cfriedline/eckertlab/projects/burt/seq/dedupe/work/samtools1.3/pheno/evolution2016_sample_info.txt\", sep=\"\\t\")\n",
    "    pheno.index = pheno['name']\n",
    "    pheno = pheno.drop(\"name\", axis=1)\n",
    "    return pheno\n",
    "pheno = get_pheno()\n",
    "pheno['state'] = pheno.population.apply(lambda x: x.split(\"-\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[(k, v.shape) for k, v in z12_dfs.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_correction(n):\n",
    "    #for finite sample size\n",
    "    return (2*n)/(2*n-1)\n",
    "\n",
    "def get_allele_freqs(locus, debug):\n",
    "    c = locus[locus != -1].value_counts()\n",
    "    total_alleles = 2.0*sum(c)\n",
    "    num_individuals = sum(c)\n",
    "    P = 0\n",
    "    Q = 0\n",
    "    PQ = 0\n",
    "    if 0 in c:\n",
    "        P = 2*c[0]\n",
    "    if 2 in c:\n",
    "        Q = 2*c[2]\n",
    "    if 1 in c:\n",
    "        PQ = c[1]\n",
    "    P += PQ\n",
    "    Q += PQ\n",
    "    if total_alleles == 0:\n",
    "        return None\n",
    "    p = P/total_alleles\n",
    "    q = Q/total_alleles\n",
    "    assert p + q == 1.0\n",
    "    He = 2 * p * q * get_correction(num_individuals)\n",
    "    Ho = PQ*1.0/num_individuals\n",
    "    Fis = 1 - (Ho/He)\n",
    "    #print p, q, He, Ho, Fis\n",
    "    \n",
    "        \n",
    "    ret = pd.Series({\"p\":p, \n",
    "                      \"q\":q,\n",
    "                      \"P\":P,\n",
    "                      \"Q\":Q,\n",
    "                      \"He\":He,\n",
    "                      \"Ho\":Ho, \n",
    "                      \"Fis\":Fis})\n",
    "    if debug:\n",
    "        print(ret)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ni_stats = pickle.load(open(os.path.join(ni_dir, \"combined_stats.pkl\"), \"rb\"))\n",
    "imp_stats = pickle.load(open(os.path.join(imp_dir, \"combined_stats.pkl\"), \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_pos(key):\n",
    "    d = pd.read_csv(\"{}.pos\".format(key), header=None, sep=\"\\t\", names=[\"ctg\", \"position\"])\n",
    "    d['snp_name'] = d.apply(lambda x: \"{}-{}\".format(x.ctg, x.position), axis=1)\n",
    "    return d\n",
    "\n",
    "def get_stat(key, col):\n",
    "    stat = ni_stats\n",
    "    spp = os.path.basename(os.path.dirname(key))\n",
    "    if \"beagle40\" in key:\n",
    "        stat = imp_stats\n",
    "    snp_pos = get_pos(key)\n",
    "    return stat[spp][0][col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ni_keys = [x for x in z12_dfs if not 'beagle40' in x]\n",
    "for key in ni_keys:\n",
    "    key2 = key.replace(\"samtools1.3\", \"samtools1.3/beagle40\")\n",
    "    mafs0 = get_stat(key, \"MAF\")\n",
    "    mafs1 = get_stat(key2, \"MAF\")\n",
    "    j = pd.concat([mafs0, mafs1], join=\"inner\", axis=1)\n",
    "    j.columns = [\"maf_ni\", \"maf_imp\"]\n",
    "    plt.scatter(j['maf_ni'], j['maf_imp'])\n",
    "    plt.title(\"{} MAF\".format(os.path.basename(os.path.dirname(key))))\n",
    "    plt.xlabel(\"not imputed\")\n",
    "    plt.ylabel(\"imputed\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_locus(name):\n",
    "    return \"-\".join(name.rsplit(\"_\", 1))\n",
    "\n",
    "def swap_alleles(locus, af):\n",
    "    locus_id = convert_locus(locus.name)\n",
    "    freqs = af.ix[locus_id]\n",
    "    if freqs['MAF'] == freqs[\"A1_freq\"]:\n",
    "        return locus.replace({0:2,2:0})\n",
    "    return locus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_swapped = {}\n",
    "for k, v in z12_dfs.items():\n",
    "    print(k)\n",
    "    allele_freqs = get_stat(k, ['A1_freq', \"MAF\"])\n",
    "    z12_swapped[k] = v.apply(swap_alleles, args=(allele_freqs,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_swapped[test_key].ix[:,0:5].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_dfs[test_key].ix[:,0:5].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pop_id = {}\n",
    "i = 1\n",
    "for p in sorted(pheno.population.unique()):\n",
    "    pop_id[p] = i\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "state_id = {}\n",
    "i = 1\n",
    "for p in sorted(pheno.state.unique()):\n",
    "    state_id[p] = i\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "state_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def assign_popid(series):\n",
    "    p = series.name.rsplit(\"-\", 1)[0]\n",
    "    series['popid'] = pop_id[p]\n",
    "    return series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z12_swapped_pop = {key: value.apply(assign_popid, axis=1) for (key, value) in z12_swapped.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def center_and_standardize_value(val, u, var):\n",
    "    if val == -1:\n",
    "        return 0.0\n",
    "    return (val-u)/np.sqrt(var)\n",
    "\n",
    "def center_and_standardize(locus, af):\n",
    "    if \"_\" in locus.name:\n",
    "        locus_id = convert_locus(locus.name)\n",
    "        maf = af.ix[locus_id]\n",
    "        var = maf*(1-maf)\n",
    "        u = np.mean([x for x in locus if x != -1])\n",
    "        return locus.apply(center_and_standardize_value, args=(u, var))\n",
    "    return locus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std = {}\n",
    "for k, df in z12_swapped_pop.items():\n",
    "    print(k)\n",
    "    allele_freqs = get_stat(k, \"MAF\")\n",
    "    pca_std[k] = df.apply(center_and_standardize, args=(allele_freqs,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(pca_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std[test_key].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std_data = {key: value.ix[:,:-1] for (key, value) in pca_std.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k in pca_std_data:\n",
    "    outdir = os.path.dirname(k)\n",
    "    fname = os.path.join(outdir, \"pca_std_data.txt\")\n",
    "    print(fname)\n",
    "    pca_std_data[k].to_csv(fname, header=True, index=True, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_data_files = sorted(list(pca_std_data.keys()))\n",
    "pca_data_files = [os.path.join(os.path.dirname(x), \"pca_std_data.txt\") for x in pca_data_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%R -i pca_data_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "library(data.table)\n",
    "run_pca = function(data_file) {\n",
    "    print(data_file)\n",
    "    d = fread(data_file, sep=\"\\t\", data.table=F)\n",
    "    rownames(d) = d$V1\n",
    "    drops = c(\"V1\")\n",
    "    d = d[,!(names(d) %in% drops)]\n",
    "    res = prcomp(d, scale=F, center=F)\n",
    "    rownames(res$x) = rownames(d)\n",
    "    fname = 'pca_res.rds'\n",
    "    out = file.path(dirname(data_file), fname)\n",
    "    print(out)\n",
    "    saveRDS(res, out)\n",
    "    return(out)\n",
    "}\n",
    "results = lapply(pca_data_files, run_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca_result_files = !find /gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3 -name \"pca_res.rds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_results = {}\n",
    "for i, f in enumerate(pca_result_files):\n",
    "    print(f)\n",
    "    var = \"res{}\".format(i)\n",
    "    r(\"res{}=readRDS('{}')\".format(i, f))\n",
    "    pca_results[f] = var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_pca_x(res):\n",
    "    x = pd.DataFrame(pandas2ri.ri2py(res.rx2(\"x\")))\n",
    "    x.index = res.rx2(\"x\").names[0]\n",
    "    x.columns = res.rx2(\"x\").names[1]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summary = r('summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_x = {}\n",
    "for key, var in pca_results.items():\n",
    "    pca_x[key] = get_pca_x(r[var])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def imputed_name(key):\n",
    "    if 'beagle' in key:\n",
    "        return \"imputed\"\n",
    "    return \"not_imputed\"\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "def plot_pca(key, pca_std, pca_std_data, pca_x, prcomp_res, pheno, color_by):\n",
    "    pop_dict = pop_id\n",
    "    pop_key = color_by\n",
    "    if color_by == \"state\":\n",
    "        pop_dict = state_id\n",
    "    \n",
    "    joined = pd.concat([pca_std_data, pca_x, pheno], join=\"inner\", axis=1)\n",
    "    legend_dict = {}\n",
    "    legend_idx = 0\n",
    "    for elem in sorted(joined[color_by].unique()):\n",
    "        legend_dict[elem] = legend_idx\n",
    "        legend_idx+=1\n",
    "        \n",
    "    norm = mcolors.Normalize(0, len(legend_dict))\n",
    "\n",
    "    legend = {}\n",
    "    \n",
    "    for row in joined.iterrows():\n",
    "        pop =row[1][pop_key]\n",
    "        n = norm(legend_dict[pop])\n",
    "        color=cm.rainbow(n)\n",
    "        legend[pop] = color\n",
    "        plt.scatter(row[1].PC1, \n",
    "                    row[1].PC2, \n",
    "                    s=50, \n",
    "                    c=color)\n",
    "    fig = plt.gcf()\n",
    "    ax = plt.gca()\n",
    "    cmap = plt.get_cmap()\n",
    "    fig.set_size_inches(10,8)\n",
    "    \n",
    "    imp = summary(prcomp_res).rx(\"importance\")[0]\n",
    "    plt.xlabel(\"PC1 (%g)\" % imp.rx(2,1)[0])\n",
    "    plt.ylabel(\"PC2 (%g)\" % imp.rx(2,2)[0])\n",
    "\n",
    "    handles = []\n",
    "    for pop in sorted(legend):\n",
    "        handles.append(mpatches.Patch(color=legend[pop], label=pop))\n",
    "    plt.legend(handles=handles)\n",
    "    \n",
    "    out_file = \"{}-{}-{}-{}.pdf\".format(os.path.basename(os.path.dirname(key)),\n",
    "                                        imputed_name(key),\n",
    "                                        os.path.basename(key),\n",
    "                                        color_by)\n",
    "    \n",
    "    plt.title(\"PCA of n={} {} samples on {} loci ({})\".format(len(joined), \n",
    "                                                              joined.species[0].lower(), \n",
    "                                                              len(pca_std_data.columns), \n",
    "                                                              imputed_name(key)))\n",
    "    sns.despine()\n",
    "    plt.savefig(out_file)\n",
    "    plt.show()\n",
    "    return out_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def get_pca_std(pca_results_key):\n",
    "    for k in pca_std:\n",
    "        if os.path.dirname(k) == os.path.dirname(pca_results_key):\n",
    "            return pca_std[k]\n",
    "    return None\n",
    "\n",
    "def get_pca_std_data(pca_results_key):\n",
    "    for k in pca_std_data:\n",
    "        if os.path.dirname(k) == os.path.dirname(pca_results_key):\n",
    "            return pca_std_data[k]\n",
    "    return None\n",
    "\n",
    "for key, var in pca_results.items():\n",
    "    for color_by in ['state', 'population']:\n",
    "        f = plot_pca(key, get_pca_std(key), get_pca_std_data(key), pca_x[key], r[var], pheno, color_by)\n",
    "        display(FileLink(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_df(dirname, fname, df):\n",
    "    f = os.path.join(dirname, \"%s.txt\" % fname) \n",
    "    df.to_csv(f, \n",
    "              header=True,\n",
    "              index=True,\n",
    "              sep=\"\\t\")\n",
    "    print(\"saved %s\" % f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std_data_files = !find /gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3 -name \"pca_std_data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_std_data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%R -i pca_std_data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "library(data.table)\n",
    "source(\"tw_calc.R\")\n",
    "test=read.table(\"twtable\", header=F)\n",
    "\n",
    "run_tw = function(pca_data_file) {\n",
    "    d = fread(pca_data_file, sep=\"\\t\", data.table=F)\n",
    "    rownames(d) = d$V1\n",
    "    drops = c(\"V1\")\n",
    "    d = d[,!(names(d) %in% drops)]\n",
    "    return(TWcalc(as.matrix(d),20))\n",
    "}\n",
    "tw_results = lapply(pca_std_data_files, run_tw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tws = {}\n",
    "for i, f in enumerate(pca_data_files):\n",
    "    ri = i + 1\n",
    "    tws[f] = r('tw_results[[{}]][[2]]'.format(ri))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tws = [r(\"tw_ni[[2]]\"), r(\"tw_imp[[2]]\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_sig_tracywidom(tw_p):\n",
    "    ps = []\n",
    "    for i, p in enumerate(tw_p):\n",
    "        if p > 0.05:\n",
    "            #print(i, p)\n",
    "            break\n",
    "        else:\n",
    "            ps.append(p)\n",
    "    return len(ps), ps\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tw_nums = {}\n",
    "for key in sorted(tws):\n",
    "    pvals = tws[key]\n",
    "    t = get_sig_tracywidom(pvals)[0]\n",
    "    print(key, t)\n",
    "    tw_nums[key] = t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tracy-Widom\n",
    "\n",
    "| Sample| TW |\n",
    "|-------|---------|\n",
    "| /gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3/P/pca_std_data.txt | 1 |\n",
    "| /gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3/beagle40/P/pca_std_data.txt | 2 |\n",
    "| /gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3/beagle40/G/pca_std_data.txt | 11 |\n",
    "| /gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3/T/pca_std_data.txt | 9 |\n",
    "| /gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3/E/pca_std_data.txt | 2 |\n",
    "| /gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3/beagle40/T/pca_std_data.txt | 9 |\n",
    "| /gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3/beagle40/E/pca_std_data.txt | 3 |\n",
    "| /gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3/G/pca_std_data.txt | 11 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key, df in z12_swapped.items():\n",
    "    d = os.path.dirname(key)\n",
    "    save_df(d, \"z12_swapped\", df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca_cov = {}\n",
    "for k, v in tw_nums.items():\n",
    "    pca_x_key = os.path.join(os.path.dirname(k), \"pca_res.rds\")\n",
    "    x = pca_x[pca_x_key]\n",
    "    pca_cov[k] = x.ix[:,0:v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in sorted(pca_cov):\n",
    "    out = os.path.join(os.path.dirname(key), \"{}-{}-pca_cov.txt\".format(os.path.basename(os.path.dirname(key)), \n",
    "                                                                        imputed_name(key)))\n",
    "    print(out)\n",
    "    pca_cov[key].to_csv(out, sep=\"\\t\", header=True, index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
