{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../include_utils\")\n",
    "\n",
    "#from IPython.parallel import Client\n",
    "import ipyparallel as ipp\n",
    "import os, time\n",
    "import include_utils as u\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import numbers\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "import vcf\n",
    "from sklearn import preprocessing\n",
    "from subprocess import Popen, PIPE\n",
    "import seaborn as sns\n",
    "from IPython.display import FileLink\n",
    "import urllib.request as urllib2\n",
    "import dill\n",
    "import traceback\n",
    "from pandas import Series, DataFrame\n",
    "import gzip\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore',category=pd.io.pytables.PerformanceWarning)\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from Bio import SeqIO\n",
    "import pysam\n",
    "from collections import OrderedDict, namedtuple\n",
    "import operator\n",
    "import multiprocessing as mp\n",
    "from ipyparallel import Client\n",
    "import pysam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def setup_r():\n",
    "    os.environ['R_HOME'] = '/home/cfriedline/g/R3/lib64/R'\n",
    "    os.environ['LD_LIBRARY_PATH'] = \"%s/lib:%s:%s\" % (os.environ['R_HOME'], \n",
    "                                                   os.environ['LD_LIBRARY_PATH'],\n",
    "                                                     \"/home/cfriedline/lib64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "setup_r() #skip on mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()\n",
    "r = robjects.r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "%reload_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_GQ_to_p(q):\n",
    "    return pow(10,(q/-10.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vcfutils = \"perl /home/cfriedline/g/src/bcftools-1.3/vcfutils.pl\"\n",
    "vcftools = \"/home/cfriedline/bin/vcftools\"\n",
    "bcftools = \"/home/cfriedline/gpfs/src/bcftools-1.3/bcftools\"\n",
    "tabix = \"/home/cfriedline/gpfs/src/htslib-1.3/tabix\"\n",
    "bgzip = \"/home/cfriedline/gpfs/src/htslib-1.3/bgzip\"\n",
    "java  = \"/home/cfriedline/g/src/jdk1.8.0_60/bin/java\"\n",
    "plink = \"/home/cfriedline/g/src/plink-1.07-x86_64/plink --noweb\"\n",
    "plink2 = \"/home/cfriedline/g/src/plink_beta_3.29/plink\"\n",
    "\n",
    "# For Mac\n",
    "# vcfutils = \"perl /Users/chris/src/bcftools-1.3/vcfutils.pl\"\n",
    "# vcftools = \"/Users/chris/bin/vcftools\"\n",
    "# bcftools = \"/Users/chris/src/bcftools-1.3/bcftools\"\n",
    "# tabix = \"/Users/chris/src/htslib-1.3/tabix\"\n",
    "# bgzip = \"/Users/chris/src/htslib-1.3/bgzip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "analysis_dir = '/gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3'\n",
    "vcf_file = os.path.join(analysis_dir, \"concat2.vcf.gz\")\n",
    "assert os.path.exists(vcf_file)\n",
    "vcf_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!$vcftools --remove-indels \\\n",
    "--max-missing 0.5 \\\n",
    "--min-alleles 2 \\\n",
    "--max-alleles 2 \\\n",
    "--remove-filtered-all \\\n",
    "--recode \\\n",
    "--recode-INFO-all \\\n",
    "--gzvcf \\\n",
    "$vcf_file \\\n",
    "--out $vcf_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "VCFtools - 0.1.14\n",
    "(C) Adam Auton and Anthony Marcketta 2009\n",
    "\n",
    "Parameters as interpreted:\n",
    "\t--gzvcf /gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3/concat2.vcf.gz\n",
    "\t--recode-INFO-all\n",
    "\t--max-alleles 2\n",
    "\t--min-alleles 2\n",
    "\t--max-missing 0.5\n",
    "\t--out /gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3/concat2.vcf.gz\n",
    "\t--recode\n",
    "\t--remove-filtered-all\n",
    "\t--remove-indels\n",
    "\n",
    "Using zlib version: 1.2.8\n",
    "After filtering, kept 768 out of 768 Individuals\n",
    "Outputting VCF file...\n",
    "After filtering, kept 643619 out of a possible 36629450 Sites\n",
    "Run Time = 13095.00 seconds\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vcf_filtered = \"%s.recode.vcf\" % vcf_file\n",
    "vcf_filtered_gz = \"%s.gz\" % vcf_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!$bgzip -c $vcf_filtered > {vcf_filtered_gz}\n",
    "!$tabix {vcf_filtered_gz}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_vcf_stats(args):\n",
    "    vcftools, vcf_gz, stat = args\n",
    "    res = !$vcftools --gzvcf $vcf_gz --out $vcf_gz {\"--%s\" % stat} \n",
    "    return stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samples = []\n",
    "for x in pysam.VariantFile(vcf_filtered_gz):\n",
    "    samples = list(x.samples)\n",
    "    break\n",
    "\n",
    "with open(\"evolution2016_samples.txt\", \"w\") as o:\n",
    "    for s in samples:\n",
    "        o.write(\"{}\\n\".format(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!mkdir /gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3/T\n",
    "!mkdir /gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3/E\n",
    "!mkdir /gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3/P\n",
    "!mkdir /gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3/G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spp_dict = {}\n",
    "for s in samples:\n",
    "    spp = s[0]\n",
    "    if not spp in spp_dict:\n",
    "        spp_dict[spp] = []\n",
    "    spp_dict[spp].append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filedir = \"/gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3\"\n",
    "cmds = []\n",
    "for spp in spp_dict:\n",
    "    spp_dir = os.path.join(filedir, spp)\n",
    "    with open(os.path.join(spp_dir, \"spp.txt\"), \"w\") as o:\n",
    "        for elem in spp_dict[spp]:\n",
    "            o.write(\"{}\\n\".format(elem))\n",
    "    out_vcf = os.path.join(spp_dir, \"{}-snps.vcf\".format(spp))\n",
    "    cmd = \"{3} --keep {0} --remove-filtered-all --recode --recode-INFO-all --gzvcf {1} --out {2}\".format(o.name, vcf_filtered_gz, out_vcf, vcftools)\n",
    "    cmds.append(cmd)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cmds[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rc = Client(profile=\"sge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dv, lv = u.get_views(rc)\n",
    "len(dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_cmd(cmd):\n",
    "    res  = !$cmd\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dv['run_cmd'] = run_cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "by_spp = lv.map_async(run_cmd, cmds[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "by_spp.progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats = ['depth',\n",
    "            'site-depth',\n",
    "            'site-mean-depth',\n",
    "            'site-quality',\n",
    "            'missing-indv',\n",
    "            'missing-site',\n",
    "            'freq',\n",
    "            'counts',\n",
    "            'hardy',\n",
    "            'het']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dv['get_vcf_stats'] = get_vcf_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stat_jobs = []\n",
    "for s in stats:\n",
    "    stat_jobs.append(lv.apply_async(get_vcf_stats, (vcftools, vcf_filtered_gz, s)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split_vcfs = !find $filedir -name \"*-snps.vcf.recode.vcf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "split_vcfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split_stat_args = []\n",
    "for v in split_vcfs:\n",
    "    for s in stats:\n",
    "        split_stat_args.append((vcftools, v, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "split_stat_jobs = lv.map_async(get_vcf_stats, split_stat_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "split_stat_jobs.progress, len(split_stat_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)\n",
    "\n",
    "def get_MAF(row):\n",
    "    import numpy as np\n",
    "    try:\n",
    "        return np.min([row.A1_freq, row.A2_freq])\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        \n",
    "def get_correction(n):\n",
    "    #for finite sample size\n",
    "    return (2*n)/(2*n-1)\n",
    "\n",
    "def calculate_Fis(vals):\n",
    "    import numpy as np\n",
    "    try:\n",
    "        data = [float(x) for x in vals.split(\"/\")]\n",
    "        assert len(data) == 3\n",
    "        num_individuals = np.sum(data)\n",
    "        total_alleles = 2*num_individuals\n",
    "        a1_count = 2*data[0]\n",
    "        a2_count = 2*data[2]\n",
    "        het_count = data[1]\n",
    "        a1_count += het_count\n",
    "        a2_count += het_count\n",
    "        a1_freq = a1_count/total_alleles\n",
    "        a2_freq = a2_count/total_alleles\n",
    "        assert a1_freq + a2_freq == 1.0\n",
    "        He = 2 * a1_freq * a2_freq * get_correction(num_individuals)\n",
    "        Ho = het_count/num_individuals\n",
    "        Fis = 1 - (Ho/He)\n",
    "        return Fis\n",
    "    except:\n",
    "        return -9\n",
    "\n",
    "def combine_vcf_stats(args):\n",
    "    filedir, prefix = args\n",
    "    print(filedir, prefix)\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    hardy_files = !ls {filedir}/{prefix}*.hwe\n",
    "    print(hardy_files)\n",
    "    hardy = pd.read_csv(hardy_files[0], sep=\"\\t\")\n",
    "\n",
    "    hardy.columns = ['CHROM', 'POS', 'OBS(HOM1/HET/HOM2)', 'E(HOM1/HET/HOM2)', 'ChiSq_HWE',\n",
    "       'P_HWE', 'P_HET_DEFICIT', 'P_HET_EXCESS']\n",
    "    hardy.index = hardy.apply(lambda x: \"%s-%d\" % (x.CHROM, x.POS), axis=1)\n",
    "    \n",
    "    loci_files = !ls {filedir}/{prefix}*.l* | grep -v log\n",
    "    print(loci_files)\n",
    "    loci_df = pd.concat([pd.read_csv(x, sep=\"\\t\", skiprows=0) for x in loci_files], axis=1)\n",
    "    chrom_pos = loci_df.ix[:,0:2]\n",
    "    \n",
    "    frq_files = !ls {filedir}/{prefix}*.frq* | grep -v count\n",
    "    print(frq_files)\n",
    "    frq_data = []\n",
    "    h = open(frq_files[0])\n",
    "    header = h.readline().strip().split()\n",
    "    for line in h:\n",
    "        frq_data.append(line.strip().split('\\t'))\n",
    "\n",
    "    header = ['CHROM', 'POS', 'N_ALLELES', 'N_CHR', 'A1_FREQ', \"A2_FREQ\"]\n",
    "    frq_df = pd.DataFrame(frq_data)\n",
    "    print(frq_df.columns)\n",
    "    #frq_df = frq_df.drop([6,7],axis=1)\n",
    "    frq_df.columns = header\n",
    "    frq_df.index = frq_df.apply(lambda x: \"%s-%s\" % (x.CHROM, x.POS), axis=1)\n",
    "    \n",
    "    loci_df = loci_df.drop(['CHROM','CHR','POS'], axis=1)\n",
    "    loci_df = pd.concat([chrom_pos, loci_df], axis=1)\n",
    "    loci_df.index = loci_df.apply(lambda x: \"%s-%d\" % (x.CHROM, x.POS), axis=1)\n",
    "    \n",
    "    loci_df = pd.concat([loci_df, frq_df, hardy], axis=1)\n",
    "    loci_df[\"A1_allele\"] = loci_df.apply(lambda row: row.A1_FREQ.split(\":\")[0], axis=1)\n",
    "    loci_df[\"A2_allele\"] = loci_df.apply(lambda row: row.A2_FREQ.split(\":\")[0], axis=1)\n",
    "    \n",
    "    loci_df[\"A1_freq\"] = loci_df.apply(lambda row: float(row.A1_FREQ.split(\":\")[1]), axis=1)\n",
    "    loci_df[\"A2_freq\"] = loci_df.apply(lambda row: float(row.A2_FREQ.split(\":\")[1]), axis=1)\n",
    "    \n",
    "    loci_df['MAF'] = loci_df.apply(get_MAF, axis=1)\n",
    "    loci_df = loci_df.drop(['CHROM', 'POS'], axis=1)\n",
    "    \n",
    "    loci_df['Fis'] = loci_df['OBS(HOM1/HET/HOM2)'].apply(calculate_Fis)\n",
    "    \n",
    "    return loci_df, frq_df, hardy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dv['combine_vcf_stats'] = combine_vcf_stats\n",
    "dv['calculate_Fis'] = calculate_Fis\n",
    "dv['get_MAF'] = get_MAF\n",
    "dv['get_correction'] = get_correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spp_dirs = [\"T\", \"E\", \"P\", \"G\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined_stats_jobs = {}\n",
    "for spp in spp_dirs:\n",
    "    print(spp)\n",
    "    d = os.path.join(analysis_dir, spp)\n",
    "    combined_stats_jobs[spp] = lv.apply_async(combine_vcf_stats, (d, spp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k, v in combined_stats_jobs.items():\n",
    "    print(v.ready())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_stats = {}\n",
    "for spp in combined_stats_jobs:\n",
    "    combined_stats[spp] = combined_stats_jobs[spp].r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined_stats[\"T\"][0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pickle.dump(combined_stats, open(os.path.join(analysis_dir, \"combined_stats.pkl\"), \"wb\"), pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#loci_df, frq_df, hardy = combine_vcf_stats(analysis_dir, \"samtools\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute genotypes with beagle\n",
    "\n",
    "```bash\n",
    "cd /gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3\n",
    "mkdir beagle40\n",
    "cd beagle40\n",
    "ln -s ../concat2.vcf.gz.recode.vcf.gz\n",
    "\n",
    "> cat beagle.q\n",
    "#$ -S /bin/bash\n",
    "#$ -cwd\n",
    "#$ -V\n",
    "#$ -N beagle\n",
    "#$ -pe smp 64\n",
    "#$ -o beagle.out\n",
    "#$ -e beagle.err\n",
    "#$ -q godel199@godel97\n",
    "\n",
    "~/g/src/jdk1.8.0_92/bin/java -jar ~/g/src/BEAGLE4/beagle.r1399.jar \\\n",
    "gl=concat2.vcf.gz.recode.vcf.gz \\\n",
    "out=/tmp/cfriedline/beagle40 \\\n",
    "nthreads=64 \\\n",
    "phase-its=10 \\\n",
    "burnin-its=10 \\\n",
    "impute-its=10\n",
    "\n",
    "cp /tmp/cfriedline/beagle40* /gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3/beagle40\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beagle_dir = os.path.join(analysis_dir, \"beagle40\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beagle_vcf_gz = os.path.join(beagle_dir, \"beagle40.vcf.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert os.path.exists(beagle_vcf_gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!vcftools --gzvcf {beagle_vcf_gz}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir /gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3/beagle40/T\n",
    "!mkdir /gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3/beagle40/E\n",
    "!mkdir /gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3/beagle40/P\n",
    "!mkdir /gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3/beagle40/G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp_cmds = []\n",
    "for spp in spp_dict:\n",
    "    spp_dir = os.path.join(\"/gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3/beagle40\", spp)\n",
    "    with open(os.path.join(spp_dir, \"spp.txt\"), \"w\") as o:\n",
    "        for elem in spp_dict[spp]:\n",
    "            o.write(\"{}\\n\".format(elem))\n",
    "    out_vcf = os.path.join(spp_dir, \"{}-snps.vcf\".format(spp))\n",
    "    cmd = \"{3} --keep {0} --remove-filtered-all --recode --recode-INFO-all --gzvcf {1} --out {2}\".format(o.name, beagle_vcf_gz, out_vcf, vcftools)\n",
    "    imp_cmds.append(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imp_cmds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp_by_spp = lv.map_async(run_cmd, imp_cmds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp_split_vcfs = !find $filedir/beagle40 -name \"*-snps.vcf.recode.vcf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp_split_stat_args = []\n",
    "for v in imp_split_vcfs:\n",
    "    for s in stats:\n",
    "        imp_split_stat_args.append((vcftools, v, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp_split_stat_jobs = lv.map_async(get_vcf_stats, imp_split_stat_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imp_split_stat_jobs.progress, len(imp_split_stat_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imp_combined_stats_jobs = {}\n",
    "for spp in spp_dirs:\n",
    "    print(spp)\n",
    "    d = os.path.join(\"{}/beagle40\".format(analysis_dir), spp)\n",
    "    imp_combined_stats_jobs[spp] = lv.apply_async(combine_vcf_stats, (d, spp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for k, v in imp_combined_stats_jobs.items():\n",
    "    print(v.ready())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp_combined_stats = {}\n",
    "for spp in imp_combined_stats_jobs:\n",
    "    imp_combined_stats[spp] = imp_combined_stats_jobs[spp].r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined stats\n",
    "\n",
    "For each species, combined_stats is:\n",
    "\n",
    "1. loci_df\n",
    "2. freq_df\n",
    "3. hardy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(imp_combined_stats, open(os.path.join(\"{}/beagle40\".format(analysis_dir), \"combined_stats.pkl\"), \"wb\"), \n",
    "            pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for spp in combined_stats:\n",
    "    loci_df = combined_stats[spp][0]\n",
    "    chroms = sorted(set([x.split(\"-\")[0] for x in loci_df.index]))\n",
    "    out_dir = os.path.join(analysis_dir, spp)\n",
    "    with open(os.path.join(out_dir, \"chrom_map.txt\"), \"w\") as o:\n",
    "        for i, c in enumerate(chroms):\n",
    "            o.write(\"%s\\t%d\\n\" % (c, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for spp in imp_combined_stats:\n",
    "    loci_df = imp_combined_stats[spp][0]\n",
    "    chroms = sorted(set([x.split(\"-\")[0] for x in loci_df.index]))\n",
    "    out_dir = os.path.join(\"{}/beagle40\".format(analysis_dir), spp)\n",
    "    with open(os.path.join(out_dir, \"chrom_map.txt\"), \"w\") as o:\n",
    "        for i, c in enumerate(chroms):\n",
    "            o.write(\"%s\\t%d\\n\" % (c, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def write_plink_files(args):\n",
    "    vcftools, vcf_gz, chrom_map = args\n",
    "    cmd = \"{0} --gzvcf {1} --out {1} --plink --chrom-map {2}\".format(vcftools, vcf_gz, chrom_map)\n",
    "    return cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plink_args = []\n",
    "for spp in combined_stats:\n",
    "    v = os.path.join(\"{}/{}\".format(analysis_dir, spp), \"{}-snps.vcf.recode.vcf.gz\".format(spp))\n",
    "    c = os.path.join(\"{}/{}\".format(analysis_dir, spp), \"chrom_map.txt\")\n",
    "    plink_args.append(write_plink_files((vcftools, v, c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp_plink_args = []\n",
    "for spp in imp_combined_stats:\n",
    "    v = os.path.join(\"{}/{}\".format(\"{}/beagle40\".format(analysis_dir), spp), \"{}-snps.vcf.recode.vcf.gz\".format(spp))\n",
    "    c = os.path.join(\"{}/{}\".format(\"{}/beagle40\".format(analysis_dir), spp), \"chrom_map.txt\")\n",
    "    imp_plink_args.append(write_plink_files((vcftools, v, c)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plink_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imp_plink_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plink_jobs = lv.map_async(run_cmd, plink_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp_plink_jobs = lv.map_async(run_cmd, imp_plink_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plink_jobs.progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imp_plink_jobs.progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_plink_recode(args):\n",
    "    plink, vcf_gz = args\n",
    "    cmd = \"{0} --recodeA --tab --file {1} --out {1}_recodeA\".format(plink, vcf_gz)\n",
    "    return cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "peds = !find /gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3  -maxdepth 2 -name \"*.ped\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp_peds = !find /gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3/beagle40  -maxdepth 2 -name \"*.ped\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imp_peds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recode_args = []\n",
    "for p in peds:\n",
    "    v = p.replace(\".ped\", \"\")\n",
    "    recode_args.append(write_plink_recode((plink, v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp_recode_args = []\n",
    "for p in imp_peds:\n",
    "    v = p.replace(\".ped\", \"\")\n",
    "    imp_recode_args.append(write_plink_recode((plink, v)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imp_recode_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recode_jobs = lv.map_async(run_cmd, recode_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recode_jobs.progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp_recode_jobs = lv.map_async(run_cmd, imp_recode_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imp_recode_jobs.progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for spp in combined_stats:\n",
    "    loci_df = combined_stats[spp][0]\n",
    "    print(spp, loci_df.SUM_DEPTH.describe())\n",
    "    loci_df.to_csv(os.path.join(analysis_dir, \"{}_loci_stats.txt\".format(spp)),\n",
    "              sep=\"\\t\",\n",
    "              index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for spp in combined_stats:\n",
    "    loci_df = combined_stats[spp][0]\n",
    "    print(spp)\n",
    "    print(len(loci_df[loci_df.Fis == -9]))\n",
    "    print(len(loci_df[loci_df.QUAL >= 10]) - len(loci_df[loci_df.QUAL >= 20]))\n",
    "    print(len(loci_df[loci_df.QUAL < 20]), len(loci_df[loci_df.QUAL < 10]))\n",
    "    print(len(loci_df[loci_df.Fis >= 0.5]), len(loci_df[loci_df.Fis <= -0.5]), len(loci_df[loci_df.MAF < 0.01]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_snps(df, imputed=False):\n",
    "    if imputed:\n",
    "        return df[(df.MAF >= 0.01) & \n",
    "                  (df.Fis < 0.5) & \n",
    "                  (df.Fis > -0.5)]\n",
    "    else:\n",
    "        return df[(df.SUM_DEPTH >= 50) & \n",
    "                  (df.SUM_DEPTH < 1500) & \n",
    "                  (df.QUAL >= 20) & \n",
    "                  (df.MAF >= 0.01) & \n",
    "                  (df.Fis < 0.5) & \n",
    "                  (df.Fis > -0.5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loci_stage1 = {}\n",
    "for spp in spp_dirs:\n",
    "    loci_stage1[spp] = filter_snps(combined_stats[spp][0])\n",
    "    print(spp, loci_stage1[spp].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "beagle_stage1 = {}\n",
    "for spp in spp_dirs:\n",
    "    beagle_stage1[spp] = filter_snps(imp_combined_stats[spp][0], imputed=True)\n",
    "    print(spp, beagle_stage1[spp].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for spp in spp_dirs:\n",
    "    with open(os.path.join(\"{}/{}\".format(analysis_dir, spp), \"stage1_positions.txt\"), \"w\") as o:\n",
    "        for elem in loci_stage1[spp].index:\n",
    "            o.write(\"%s\\n\" % \"\\t\".join(elem.split(\"-\")))\n",
    "\n",
    "    with open(os.path.join(\"{}/{}\".format(beagle_dir, spp), \"stage1_positions.txt\"), \"w\") as o:\n",
    "        for elem in beagle_stage1[spp].index:\n",
    "            o.write(\"%s\\n\" % \"\\t\".join(elem.split(\"-\")))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "good_args = []\n",
    "for spp in spp_dirs:\n",
    "    for d in [analysis_dir, beagle_dir]:\n",
    "        d = os.path.join(d, spp)\n",
    "        v = os.path.join(d, \"{}-snps.vcf.recode.vcf.gz\".format(spp))\n",
    "        p = os.path.join(d, \"stage1_positions.txt\")\n",
    "        out = os.path.join(d, \"good_snps.vcf\")\n",
    "        cmd = \"{} --gzvcf {} --remove-filtered-all --recode --recode-INFO-all --positions {} --out {}\".format(vcftools, v, p, out)\n",
    "        good_args.append(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "good_jobs = lv.map_async(run_cmd, good_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "good_jobs.progress, len(good_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zip and index good snps\n",
    "\n",
    "```\n",
    "find . -name \"good*.recode.vcf.gz\" | parallel tabix {}\n",
    "find . -name \"good*.recode.vcf\" | parallel bgzip -c {} \\> {}.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_intersection(imp, ni):\n",
    "    return set.intersection(set(ni.index), set(imp.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "isect = {}\n",
    "for spp in spp_dirs:\n",
    "    isect[spp] = get_intersection(beagle_stage1[spp], loci_stage1[spp])\n",
    "    isect[spp] = sorted(isect[spp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for spp in isect:\n",
    "    print(spp, len(loci_stage1[spp].index), len(beagle_stage1[spp].index), len(isect[spp]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for spp in spp_dirs:\n",
    "    for d in [analysis_dir, beagle_dir]:\n",
    "        d = os.path.join(d, spp)\n",
    "        with open(os.path.join(d, \"isect_positions.txt\"), \"w\") as o:\n",
    "            for elem in isect[spp]:\n",
    "                o.write(\"%s\\n\" % \"\\t\".join(elem.split(\"-\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "isect_args = []\n",
    "for spp in spp_dirs:\n",
    "    for d, vcf_gz in zip([analysis_dir, beagle_dir], [vcf_filtered_gz, beagle_vcf_gz]):\n",
    "        d = os.path.join(d, spp)\n",
    "        v = os.path.join(d, \"good_snps.vcf.recode.vcf.gz\")\n",
    "        p = os.path.join(d, \"isect_positions.txt\")\n",
    "        o = os.path.join(d, \"isect_snps\")\n",
    "        cmd = \"{} --gzvcf {} --remove-filtered-all --recode --recode-INFO-all --positions {} --out {}\".format(vcftools, v, p, o)\n",
    "        isect_args.append(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "isect_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "isect_jobs = lv.map_async(run_cmd, isect_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "isect_jobs.progress, len(isect_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### zip and index isect snps\n",
    "\n",
    "```\n",
    "find . -name \"isect_snps.recode.vcf\" | parallel --bar bgzip -c {} \\> {}.gz\n",
    "find . -name \"isect_snps.recode.vcf.gz\" | parallel --bar tabix\n",
    "```\n",
    "\n",
    "### sort, zip, index\n",
    "\n",
    "```\n",
    "find . -name \"isect_snps.recode.vcf.gz\" | parallel --bar vcf-sort {} \\> {}_sorted.vcf\n",
    "find . -name \"isect_snps.recode.vcf.gz_sorted.vcf\" | parallel --bar bgzip -c {} \\> {}.gz\n",
    "find . -name \"isect_snps.recode.vcf.gz_sorted.vcf.gz\" | parallel --bar tabix\n",
    "```\n",
    "\n",
    "### thin, zip, index\n",
    "\n",
    "```\n",
    "find . -name \"isect_snps.recode.vcf.gz_sorted.vcf.gz\" | parallel --bar vcftools --gzvcf {} --remove-filtered-all --recode --recode-INFO-all --thin 50 --out {}_thin\n",
    "find . -name \"*thin.recode.vcf\" | parallel --bar bgzip -c {} \\> {}.gz\n",
    "find . -name \"*thin.recode.vcf.gz\" | parallel --bar tabix\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plink_file_cmds = []\n",
    "plink_recode_cmds = []\n",
    "for spp in spp_dirs:\n",
    "    for d in [analysis_dir, beagle_dir]:\n",
    "        d = os.path.join(analysis_dir, spp)\n",
    "        v = os.path.join(d, \"isect_snps.recode.vcf.gz_sorted.vcf.gz_thin.recode.vcf.gz\")\n",
    "        assert os.path.exists(f)\n",
    "        c = os.path.join(\"{}/{}\".format(analysis_dir, spp), \"chrom_map.txt\")\n",
    "        assert os.path.exists(c)\n",
    "        plink_file_cmds.append(write_plink_files((vcftools, v, c)))\n",
    "        plink_recode_cmds.append(write_plink_recode((plink, v)))\n",
    "#     write_plink_files(f)\n",
    "#     write_plink_recode(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plink_file_cmds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plink_recode_cmds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_jobs = lv.map_async(run_cmd, plink_file_cmds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_jobs.progress, len(file_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "recode_jobs = lv.map_async(run_cmd, plink_recode_cmds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "recode_jobs.progress, len(recode_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### output 012 files\n",
    "\n",
    "```\n",
    "find . -name \"isect_snps.recode.vcf.gz_sorted.vcf.gz_thin.recode.vcf.gz\" | parallel --bar vcftools --gzvcf {} --012 --out {}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!mkdir /gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3/merged\n",
    "!mkdir /gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3/beagle40/merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_merge_command(args):\n",
    "    bcftools, outdir, vcfs = args\n",
    "    cmd = \"{} merge {} -Oz -o {} --threads 16\".format(bcftools, \" \".join(vcfs), os.path.join(outdir, \"merged.vcf.gz\"))\n",
    "    return cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# merge non imputed files\n",
    "\n",
    "ni_spp_files = !find /gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3 -maxdepth 2 -name \"isect_snps.recode.vcf.gz_sorted.vcf.gz_thin.recode.vcf.gz\" \n",
    "imp_spp_files = !find /gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3/beagle40 -name \"isect_snps.recode.vcf.gz_sorted.vcf.gz_thin.recode.vcf.gz\" \n",
    "print(write_merge_command((bcftools, \"/gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3/merged\", ni_spp_files)))\n",
    "print()\n",
    "print(write_merge_command((bcftools, \"/gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3/beagle/merged\", imp_spp_files)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge commands\n",
    "\n",
    "```\n",
    "/home/cfriedline/gpfs/src/bcftools-1.3/bcftools merge \\\n",
    "/gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3/E/isect_snps.recode.vcf.gz_sorted.vcf.gz_thin.recode.vcf.gz \\\n",
    "/gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3/P/isect_snps.recode.vcf.gz_sorted.vcf.gz_thin.recode.vcf.gz \\\n",
    "/gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3/G/isect_snps.recode.vcf.gz_sorted.vcf.gz_thin.recode.vcf.gz \\\n",
    "/gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3/T/isect_snps.recode.vcf.gz_sorted.vcf.gz_thin.recode.vcf.gz \\ \n",
    "-Oz -o /gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3/merged/merged.vcf.gz \\\n",
    "--threads 16\n",
    "```\n",
    "\n",
    "```\n",
    "/home/cfriedline/gpfs/src/bcftools-1.3/bcftools merge \\\n",
    "/gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3/beagle40/T/isect_snps.recode.vcf.gz_sorted.vcf.gz_thin.recode.vcf.gz \\\n",
    "/gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3/beagle40/E/isect_snps.recode.vcf.gz_sorted.vcf.gz_thin.recode.vcf.gz \\\n",
    "/gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3/beagle40/P/isect_snps.recode.vcf.gz_sorted.vcf.gz_thin.recode.vcf.gz \\\n",
    "/gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3/beagle40/G/isect_snps.recode.vcf.gz_sorted.vcf.gz_thin.recode.vcf.gz \\\n",
    "-Oz -o /gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3/beagle40/merged/merged.vcf.gz \\\n",
    "--threads 16\n",
    "```\n",
    "\n",
    "### create 012 files\n",
    "\n",
    "```\n",
    "find . -name \"merged.vcf.gz\" | parallel --bar tabix {}\n",
    "find . -name \"merged.vcf.gz\" | parallel --bar vcftools --gzvcf {} --thin 50 --recode --recode-INFO-all --out {}_thin\n",
    "find . -name \"merged.vcf.gz_thin*\" | parallel bgzip -c {} \\> {}.gz\n",
    "find . -name \"merged.vcf.gz_thin*.gz\" | parallel tabix {}\n",
    "find . -name \"merged.vcf.gz_thin*.gz\" | parallel --bar vcftools --gzvcf {} --012 --out {}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged_files = !find /gpfs_fs/home/eckertlab/projects/burt/seq/dedupe/work/samtools1.3 -name \"merged.vcf.gz_thin.recode.vcf.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_stat_args = []\n",
    "for m in merged_files:\n",
    "    for s in stats:\n",
    "        merged_stat_args.append((vcftools, m, s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_stat_jobs = lv.map_async(get_vcf_stats, merged_stat_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_stat_jobs.progress, len(merged_stat_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_combined_stats_args = []\n",
    "for m in merged_files:\n",
    "    merged_combined_stats_args.append((os.path.dirname(m), \"merged\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {},
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_combined_stats_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
