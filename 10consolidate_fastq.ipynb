{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os \n",
    "import multiprocessing as mp\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import pandas as pd \n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_map_dir = \"/home/cfriedline/eckertlab/BURT/plate_maps/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "plate_files = glob.glob(f\"{plate_map_dir}/*.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_plate(f):\n",
    "    df = pd.read_excel(f)\n",
    "    df.index = df.iloc[:,0]\n",
    "    df = df.drop(df.columns[0], axis=1)\n",
    "    df.index.name = None\n",
    "    df = df.reset_index().rename(columns={\"index\":\"row\"})\n",
    "    df[\"source\"] = Path(f).name\n",
    "    return df.melt(id_vars=[\"source\", \"row\"], var_name=\"col\", value_name=\"sample_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_plates = pd.concat([read_plate(x) for x in plate_files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_plates = all_plates.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_plates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_name(name):\n",
    "    try:\n",
    "        data = name.split(\"-\")\n",
    "        return pd.Series(dict(species=data[0], \n",
    "                             state=data[1], \n",
    "                             popn=data[2],\n",
    "                             ind=\"-\".join(data[3:]),\n",
    "                             full_pop=\"-\".join(data[0:3])))\n",
    "    except:\n",
    "        return pd.Series()\n",
    "all_plates = all_plates.join(all_plates.sample_name.apply(split_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_plates = all_plates[~all_plates.sample_name.isna()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derive_library_name(name):\n",
    "    if \"layout\" in name:\n",
    "        return f'Burt{name.split(\"_\")[1]}'\n",
    "    return f'Burt{name.split(\".\")[0].replace(\"plate\", \"\")}'\n",
    "all_plates[\"library\"] = all_plates.source.apply(derive_library_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(all_plates.library.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_plates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_plates.to_csv(Path(plate_map_dir, \"all_plates.txt\"), sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_plates[all_plates.sample_name==\"G-VA-1-15\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_plates.groupby(\"species\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_dir1 = \"/gpfs_fs/home/eckertlab/BURT/seq/round1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_runs = \"/home/cfriedline/eckertlab/projects/burt/seq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_files1 = []\n",
    "fastq_map1 = {}\n",
    "for root, dirs, files in os.walk(first_runs):\n",
    "    for f in files:\n",
    "        p = Path(root, f)\n",
    "        if \"fastq.gz\" in p.name and \".R1.\" in p.name:\n",
    "            sample_name = p.name.split(\".\")[0]\n",
    "            library = p.parent.name\n",
    "            fastq_files1.append(dict(sample_name=sample_name,\n",
    "                                    fastq_path=str(p),\n",
    "                                    library=library))\n",
    "            \n",
    "            if sample_name not in fastq_map1:\n",
    "                fastq_map1[sample_name] = []\n",
    "            fastq_map1[sample_name].append(str(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_data1 = []\n",
    "for k, v in fastq_map1.items():\n",
    "    fastq_data1.append(dict(sample_name=k, fastq_files=v, \n",
    "                            library=list(set([Path(x).parent.name for x in v]))[0],\n",
    "                           processed_fastq=f\"{Path(first_runs, 'dedupe', Path(v[0]).name)}\"))\n",
    "\n",
    "fastq_df1 = pd.DataFrame(fastq_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def md5(fname):\n",
    "    res = !md5sum {fname}\n",
    "    return res[0].split()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = []\n",
    "pool = mp.Pool()\n",
    "for f in fastq_df1.processed_fastq:\n",
    "    jobs.append(pool.apply_async(md5, (f,)))\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([x.ready() for x in jobs]), len(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_df1[\"md5\"] = [x.get() for x in jobs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "fastq_df1.to_csv(\"df1.txt\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = fastq_df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_file(s, d):\n",
    "    shutil.copy(s, d)\n",
    "\n",
    "pool = mp.Pool(20)\n",
    "jobs = []\n",
    "for f in df1.processed_fastq:\n",
    "    s = Path(f)\n",
    "    d = Path(dest_dir1, s.name)\n",
    "    jobs.append(pool.apply_async(copy_file, (s, d)))\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([x.ready() for x in jobs]), len(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_library = \"/home/cfriedline/eckertlab/Novogene/burt\"\n",
    "dest_dir2 = \"/gpfs_fs/home/eckertlab/BURT/seq/round2\"\n",
    "\n",
    "# these files were the result of a merge of the failed NARF libraries and the good novogene libraries using \n",
    "# a script that trevor wrote ~/eckertlab/Novogene/burt/merge_fastq.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fastq_files2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "map2 = {}\n",
    "for root, dirs,files in os.walk(Path(second_library)):\n",
    "    for f in files:\n",
    "        if \"undetermined\" not in f:\n",
    "            if f.endswith(\"fastq.gz\"):\n",
    "                p = Path(root, f)\n",
    "                if \"BURT\" in p.parent.name:# and p.parent.name != \"BURT_tmp\":\n",
    "                    if p.name not in map2:\n",
    "                        map2[p.name] = dict(lib={p.parent.name}, files=[])\n",
    "                    map2[p.name][\"files\"].append(p)\n",
    "                    map2[p.name][\"lib\"].add(p.parent.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(map2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"num_files\"] = df2.files.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.library.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2.num_files==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = []\n",
    "dupes = []\n",
    "pool = mp.Pool(20)\n",
    "for f in df2[df2.num_files==1].files:\n",
    "    dest = Path(dest_dir2) / f[0].name\n",
    "    jobs.append(pool.apply_async(copy_file, (f[0], dest)))\n",
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([x.ready() for x in jobs]), len(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_fastq(args):\n",
    "    name, fastq_list = args\n",
    "    out_dir = \"/gpfs_fs/home/eckertlab/BURT/seq/round2\"\n",
    "    out_file = os.path.join(out_dir, name)\n",
    "    cmd = \"zcat {} | /home/cfriedline/bin/bgzip -c > {}\".format(\" \".join(fastq_list), out_file)\n",
    "    return cmd\n",
    "\n",
    "def run_cmd(cmd):\n",
    "    res = !{cmd}\n",
    "    return res\n",
    "\n",
    "jobs = []\n",
    "pool = mp.Pool(20)\n",
    "for f in df2[df2.num_files==2].index:\n",
    "    files = [str(x) for x in df2.loc[f].files]\n",
    "    cmd = combine_fastq((f, files))\n",
    "    print(cmd)\n",
    "    jobs.append(\n",
    "        pool.apply_async(\n",
    "            run_cmd, (cmd,)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"df2.txt\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".py",
    "format_name": "percent",
    "format_version": "1.2",
    "jupytext_version": "1.1.5"
   }
  },
  "kernelspec": {
   "display_name": "burt",
   "language": "python",
   "name": "burt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
